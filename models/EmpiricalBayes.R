## requires installation of genlasso from https://cran.r-project.org/src/contrib/Archive/genlasso/

EmpiricalBayes <- R6Class(
  inherit = ContestModel, # or AggregateModel
  private = list(
  
  # attributes
  .nTransformations = 10000, # number of transformations of each historical season to generate the prior
  .nsim = 1000, # number of simulations to return in SimulatedIncidenceArray
  .verbose = F, # TODO Take out all the printing stuff tht's not necessary and put it into conditionals w/ this 
  .hyperparams = data.frame("mu_m" = rep(1,16), # default min peak week param
                            "mu_M" = rep(52,16), # default max peak week param
                            "theta_m" = rep(0.9,16), # default min peak wILI height param
                            "theta_M" = rep(1.1,16), # default max peak wILI height param
                            "b_r" = rep(.03,16), # default CDC baseline 
                            "nu_m" = rep(0.75,16), # default min pacing param
                            "nu_M" = rep(1.25,16), # default max pacing param
                            "region" = c(1:16)# Will tell us the region associated with each hyperparam
                            #"sigma" = 1 # Removed because it'll be a vector.
  ),

  .adjacencyMatrix = diag(16),
  .fitSigma = NULL, # DF of sigmas and regions generated by the training data fit
  .historicalData = NULL,
  .filteredData = NULL, # this is a data frame, first column is region, second column year, rest are season weeks
  .currentData = NULL, #yrs curr
  .prior = NULL, #frs 
  .priorRegions = NULL,
  .priorYears = NULL,
  .priorSigma = NULL, # These are extracted along with the priors
  .posterior = NULL, # made this the potential forcasts (posterior multiplied by weights)
  .seed = 7, # the default seed is 7 (or perhaps sample the seed if the user doesn't define one)
  .steps = 6,
  .weights = NULL, # weights
  .unweightedPosterior = NULL, # posterior estimates without weights
  .regions = NULL,
  .forecast = array(c(rep(NA,16), rep(NA,52), rep(NA,1000)),dim=c(16,52,1000)), 
  .forecastSIM = NULL,
  .gatherData = function(incmat){
    print("[.gatherData]")
    incdat <- data.frame(as.table(t(incmat$mat)))%>% rename(textdate = Var1, location = Var2, value=Freq); 
    incdat$season_year = rep(incmat$colData$season,16);
    incdat$season_week = rep(incmat$colData$season.week,16);
    return(incdat) 
  },

  .extractShapesAndHyperparams = function(){
    print("[.extractShapesAndHyperparams]"); 
    require(genlasso)
    require(tidyverse)
    require(zoo)
    require(MMWRweek)
    
    training_data <- private$.historicalData;
    private$.regions <- training_data$rnames;
    training_data_long <- private$.gatherData(incmat = training_data)
    
    dat <- training_data_long  

    output_peak_height <- vector()
    output_peak_week <- vector()
    output_qt_trajectories <- data.frame(1:52)
    colnames(output_qt_trajectories) <- "season_week"
    
    regions = c()
    seasonYears = c()
    mu_ms = c()
    mu_Ms = c()
    theta_ms = c()
    theta_Ms = c()
    sigmas <- c()
    
    for(L in unique(dat$location)){
      
      output_peak_height <- vector()
      output_peak_week <- vector()
      this_region_sigmas <- vector() 
      
      for(Y in unique(dat$season_year)){
        
        temp_dat <- dat %>% filter(season_year == Y) %>% filter(location == L) %>% arrange(season_week)
        if((length(temp_dat$value) < 10)){
          print(paste(paste("[.extractShapesAndHyperparams] Not enough data in this season. Skipping...",Y),L))
          next
        }
        
        curr_peak_height <- max(temp_dat$value)
        curr_peak_season_week <- temp_dat$season_week[which(curr_peak_height == temp_dat$value)]
        
        output_peak_height <- c(output_peak_height, curr_peak_height)
        output_peak_week <- c(output_peak_week, curr_peak_season_week)
        
        qtf <- trendfilter(y  = temp_dat$value, pos = temp_dat$season_week, ord = 2)
        cv <- cv.trendfilter(qtf, k = 5, verbose = F)  # cv$lambda.1se # plot(qtf, lambda = cv$lambda.1se)
        
        output_qt_values <- predict(qtf, lambda = cv$lambda.1se)$fit
        this_year_and_region_residual_sd <- sd(temp_dat$value - output_qt_values)
        
        interpolated_qt_values <- pmax(predict(qtf, lambda = cv$lambda.1se)$fit, 0)
        
        this_region_sigmas <- c(this_region_sigmas, this_year_and_region_residual_sd)
        
        week <- as.data.frame(1:52)
        colnames(week) <- "season_week"
        vals <- cbind.data.frame(temp_dat$season_week, interpolated_qt_values)
        colnames(vals) <- c("season_week", "qt_val")
        output <- left_join(week, vals, by = "season_week") %>% mutate(qt_val = na.approx(qt_val, na.rm = F))
        if(is.na(output$qt_val[52])){
          output$qt_val[52] <- max(output$qt_val[51] + (output$qt_val[51] - output$qt_val[50]), 0)
        }
        if(is.na(output$qt_val[1])){
          output$qt_val[1] <- max(output$qt_val[2] - (output$qt_val[3] - output$qt_val[2]), 0)
        }
        
        output_qt_trajectories <- cbind(output_qt_trajectories, trajectory = output$qt_val)
        regions = c(regions, L)
        seasonYears = c(seasonYears,Y)
      } # end loop over season years
      
      
      sigmas <- cbind(sigmas, this_region_sigmas)
      
      mu_ms <- c(mu_ms,min(output_peak_week)) # min peak week
      mu_Ms <- c(mu_Ms,max(output_peak_week)) # max peak week
      theta_ms <- c(theta_ms,min(output_peak_height)) # min peak wILI height param
      theta_Ms <- c(theta_Ms,max(output_peak_height))
      
    } # end loop over regions
    
    # Make candidate trajectories rows, not columns, to match other objects
    output_qt_trajectories <- t(output_qt_trajectories[,-1])
    output_qt_trajectories = cbind.data.frame(regions,seasonYears, output_qt_trajectories)
    colnames(output_qt_trajectories) <- c("region","year",c(1:52));
    
    private$.filteredData <- output_qt_trajectories
    
    private$.hyperparams$mu_m <- mu_ms; #min(output_peak_week) # min peak week
    private$.hyperparams$mu_M <- mu_Ms; #max(output_peak_week) # max peak week
    private$.hyperparams$theta_m <- theta_ms; #min(output_peak_height) # min peak wILI height param
    private$.hyperparams$theta_M <- theta_Ms; #max(output_peak_height) # max peak wILI height param 
    private$.hyperparams$region <- unique(dat$location)
    
    sigmas_with_regions <- data.frame(as.numeric(sigmas), regions)
    colnames(sigmas_with_regions) <- c("sigma", "region")
    private$.fitSigma <- sigmas_with_regions # was: output_noise_sd # TODO maybe needs fixing still!
    
  }
  ,
  
  .generatePrior = function(){
    
    print("[.generatePrior]");
    
    # initialize matrix that will go into private$.prior
    priorMat = matrix(rep(NA,private$.nTransformations*52), ncol=52,byrow=T);
    
    regions = c();
    sigmas = matrix(NA, ncol = 1, nrow = private$.nTransformations)
    set.seed(private$.seed)
    
    for(k in c(1:private$.nTransformations))
    {
      f_r_index = sample(1:nrow(private$.filteredData),1);# draw shape index
      regions = c(regions,as.character(private$.filteredData[f_r_index,]$region))
      
      this_mu_m = private$.hyperparams$mu_m[which(private$.hyperparams$region == private$.filteredData[f_r_index,]$region)]
      this_mu_M = private$.hyperparams$mu_M[which(private$.hyperparams$region == private$.filteredData[f_r_index,]$region)]
      
      this_theta_m = private$.hyperparams$theta_m[which(private$.hyperparams$region == private$.filteredData[f_r_index,]$region)]
      this_theta_M = private$.hyperparams$theta_M[which(private$.hyperparams$region == private$.filteredData[f_r_index,]$region)]
      
      mu_r = sample(this_mu_m:this_mu_M,1) # draw peak week
      theta_r = runif(1,this_theta_m, this_theta_M) # draw peak height
      
      # Stuff that's not region-specific
      b_r = private$.hyperparams$b_r[1]; # find cdc baseline wILI for the year - not implemented yet
      nu_r = runif(1,private$.hyperparams$nu_m[1], private$.hyperparams$nu_M[1]) # draw pacing
      
      sigmas[k,1] <- sample(private$.fitSigma[private$.fitSigma$region == private$.filteredData[f_r_index,]$region,1], size = 1, replace = TRUE)
      
      if (private$.verbose == T)
      {
        print("[fit] Prior draws:")
        print(paste("season index:",f_r_index))
        print(paste("peak week shift: ",mu_r))
        print(paste("peak height: ",theta_r))
        print(paste("cdc baseline: ",b_r))
        print(paste("pacing:",nu_r))
      };
      
      f_r = as.matrix(private$.filteredData[f_r_index,c(3:54)])
      f_r_transf = c();
      
      for(i in c(1:length(f_r))){ 
        index = round((i - mu_r)/nu_r + which(f_r==max(f_r)));
        if(index < 1) index = 1; # TODO
        if(index > length(f_r)) index = length(f_r); # TODO
        f_r_transf = c(f_r_transf,b_r + (theta_r - b_r)/(max(f_r) - b_r)*(f_r[index]));
      }
      
      priorMat[k,] = f_r_transf;
    }
    
    private$.priorRegions = regions;
    private$.prior = priorMat;
    private$.priorSigma <- sigmas;
    
  },
  
  .generatePosterior = function(){
    
    print("[.generatePosterior]");
    
    private$.weights = matrix(NA, nrow = private$.nTransformations, ncol = 1)
    private$.unweightedPosterior = data.frame(matrix(NA, private$.nTransformations, 52))
    
    set.seed(private$.seed)
    
    yrs_curr_regions = private$.currentData$rnames;
    frs_curr = private$.prior
    
    for(i in c(1:nrow(private$.currentData$mat)))  
    {
      
      frs_curr_inx = which(private$.priorRegions == yrs_curr_regions[i])
      yrs_curr = private$.currentData$mat[i,]
      
      for (j in 1:length(frs_curr_inx)){
        
        frs_curr = private$.prior[frs_curr_inx[j],]
        sigma <- private$.priorSigma[frs_curr_inx[j]]
        
        # try different method weighted by weeks in season
        weight = 0
        for (k in 1:length(yrs_curr))
        {
          weight = weight + log(1.1^k*dnorm(yrs_curr[k],mean=frs_curr[k],sd=5*sigma))
        }
        
        v_1 = c()
        for(a in c(1:length(yrs_curr))){
          v_1[a] = yrs_curr[a]
        }
        for(b in (length(yrs_curr)+1):52){
          v_1[b] = frs_curr[b]
        }
        
        private$.weights[frs_curr_inx[j]] = exp(weight)
        private$.unweightedPosterior[frs_curr_inx[j],] = v_1
        
      } # end iteration over prior
      
    } # end iteration over region
    
  },
  
  .calculateForecast = function(startingWeek){
    
    print("[.calculateForecast]")
    
    for(i in c(1:nrow(private$.currentData$mat)))
    {
      candidateRegions = which(private$.adjacencyMatrix[i,] != 0)
      # Allow borrowing across regions
      post_inx = which(private$.priorRegions %in% private$.currentData$rnames[candidateRegions])
      #post_inx = which(private$.priorRegions == private$.currentData$rnames[i])
      private$.weights[post_inx] = private$.weights[post_inx]/sum(private$.weights[post_inx])
      
      for (j in c(1:private$.nsim))
      {
        importanceWeightedIndex = rmultinom(1,1,private$.weights[post_inx])
        iwi = which(importanceWeightedIndex==1)
        private$.forecast[i,,j] <- t(private$.unweightedPosterior[iwi,])[,1]; 
      }
    }
    
    # store it all in private$.forecast, where rows are regions and cols are weighted avg.
    private$.forecastSIM = SimulatedIncidenceMatrix$new(data = private$.forecast[,(startingWeek+1):(startingWeek+private$.steps),]);
    private$.forecastSIM$rnames = as.factor(private$.regions);
  }
  
),

public = list(
  
  # attributes
  data = NULL,
  newdata = NULL,
  fit_once = T,
  # methods
  
  # fit method: nPrior is the size of the prior, steps is the number of weeks ahead.
  fit = function(fitData, nTransformations=1000, steps=6,verbose=F){
    
    print("[fit]")
    
    # debug line from Katie
    if("fit" %in% private$.debug){browser()};
    
    # assign private attribute for number of transformations and historical data
    private$.nTransformations <- nTransformations;
    private$.historicalData <- fitData;
    
    # call .extractShapesAndHyperparams
    private$.extractShapesAndHyperparams();
    
    # call .generatePrior
    private$.generatePrior();
    
  },
  
  forecast = function(newdata, steps = 6, nsim = 1000, adj = diag(16)){
    
    print("[forecast]")
    # subset the data to current season only
    last_sw = tail(newdata$colData$season.week,1);
    first_inx = ncol(newdata$mat) - last_sw + 1;
    last_inx = ncol(newdata$mat);
    newdata$subset(cols = first_inx:last_inx);
    private$.currentData = newdata;
    private$.nsim = nsim;
    private$.adjacencyMatrix = adj;
    
    print(paste("[forecast] Generating forecast from season-week:",last_sw))
    
    if(last_sw == 52) 
      {
        print("[forecast] Warning: Boundary effect. Returning the observed data from season-weeks 45-52. 'To do then now would be retro. To do then then was very now-tro. - Harry Shearer'")
        
        for(i in c(1:nrow(newdata$mat)))
        {
          private$.forecast = array(c(rep(NA,16), rep(NA,52), rep(NA,nsim)),dim=c(16,52,nsim))
          for(j in c(1:nsim)) private$.forecast[i,,j] = newdata$mat[i,]
        }
        private$.forecastSIM = SimulatedIncidenceMatrix$new(data = private$.forecast[,47:52,]);
        private$.forecastSIM$rnames = as.factor(private$.regions);
        return(IncidenceForecast$new(private$.forecastSIM, forecastTimes = rep(TRUE, steps)))
      }
    
    else if(52 - last_sw < steps) print(paste(paste("[forecast] Warning: Boundary effect. Returning forecast for week", (51 - steps)),"to 52."))
    private$.generatePosterior();
    private$.calculateForecast(min(last_sw, 51-steps));
    # return IncidenceForecast object
    return(IncidenceForecast$new(private$.forecastSIM, forecastTimes = rep(TRUE, steps)));
    
  },
  
  # Function to see what the prior curves look like.  Takes a vector. You can use sample() etc.
  plotPrior = function(indices=c(1:private$.nTransformations)){
    plot(private$.prior[indices[1],], xlim=c(0,52),ylim=c(0, max(private$.prior[indices,])),type="l",col=rainbow(length(indices))[1],xlab = "Season Week",ylab="wILI", main="Prior");
    for(i in c(2:length(indices))) {lines(private$.prior[indices[i],],col=rainbow(length(indices))[i])};
  },
  
  getHistoricalData = function(){return(private$.historicalData)},
  getFilteredData = function(){return(private$.filteredData)},
  getPrior = function(){return(private$.prior)},
  getHyperparams = function(){return(private$.hyperparams)},
  getSigmas = function(){return(private$.priorSigma)},
  getFitSigmas = function(){return(private$.fitSigma)},
  getCurrentData = function(){return(private$.currentData)},
  getWeights = function(){return(private$.weights)},
  getUnweightedPosterior = function(){return(private$.unweightedPosterior)},
  getForecast = function(){return(private$.forecast)},
  getRegions = function(){return(private$.regions)},
  getPriorRegions = function(){return(private$.priorRegions)},
  initialize = function(){}
)
)
